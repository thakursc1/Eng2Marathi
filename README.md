# Sequence2Sequence Machine Translation with Attention 

 Pytorch Implementation of [Neural Machine Translation by Jointly Learning to Align and Translate (2014)](https://arxiv.org/abs/1409.0473) 
![Attention Animation](https://github.com/thakursc1/Eng2Marathi/blob/master/gifs/read_me_attention_animation.gif)


### Highlights 
1. Use Hugging Face's custom trained BERTWordPieceTokenizer

### Dependencies
[HuggingFace/tokenizers](https://github.com/huggingface/tokenizers)
Pytorch
Numpy

### Acknowledgements
The animation was borrowed from the following [medium article](https://towardsdatascience.com/attn-illustrated-attention-5ec4ad276ee3)
